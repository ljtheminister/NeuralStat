\documentclass{article}
\usepackage[margin=1.0in]{geometry}
\usepackage{graphicx, algorithmic, algorithm}


\begin{document}
\date{}
\title{Decoding of reaching movements of monkeys}
\author{John Min\\ jcm2199}
\maketitle

\section{Introduction}

The field of brain-machine interfaces (BMIs) is ebulliently researching the optimal input signal source for desired applications.  Because intracortical electrodes deterioriate significantly after several years, recording single neuron action potentials or spikes, the signals with highest bandwith, becomes difficult.  Fortunately, field potentials recorded within the cortex (local field potentials, LFPs), at its surface (electrocorticograms, ECoG), and at the dural surface (epidural, EFPs) also contain significant information.  Flint et. al[1] analyzes data on monkey arm reaching movements and scrutinizes decoding performance of velocity, position, and target classification between spikes, LFPs, and EFPs.  The study demonstrates that the LFP contains significant movement-related information, even in the absence of spike records on the same electrodes, and thus, concludes that LFPs could provide a robust, accurate signal source for BMIs.  Consequently, this paper investigates an alternative methodology, seeking to improve prediction rates on the reach movement classification task.  


\section{Flint et. al (2012)}
\subsection{Experiment}
A rhesus monkey was trained to perform an eight-target, center-out task while holding onto a two-link manipulandum.  Eight 2 cm square outer targets spaced at 45$\,^{\circ}$ intervals around a circle of radius 10 cm.  Each trial begins with the illumination of the center target.  After a random hold time of 0.5-0.6 seconds, the center target disappears and a randomly selected outer target is illuminated, signaling the monkey to perform a reach movement.  The monkey must reach the outer target within 1.5 seconds and hold for a random time between 0.2 and 0.4 seconds to obtain a liquid reward.  

\subsection{Electrode recording}
Field potentials were obtained by band-pass filtering between 0.5 and 500 Hz and sampling at 2 kHz.  The signals were then digitally notch filtered at 120, 180, and 240 Hz to remove line noise.  

\subsection{Methodology: feature extraction, feature selection, and decoder}
\noindent
Flint et. al (2012) convert the spike signals to firing rates in 100 ms bins, extracting five features from each field potential signal:  the local motor potential (LMP), defined as the moving average within a 256 ms window, and the power in four different frequency bands (0-4, 7-20, 70-200, and 200-300 Hz).  The windows are overlapped by 156 ms to provide a sample every 100 ms.  After applying a Hanning window, fast Fourier transforms are applied to 256 ms windows to compute the power in each band.   \\

\noindent
The band power values (or spike firing rates) in seven time bins from 200 ms before to 500 ms after movement onset (as determined from the manipulandum's velocity) are used as features, providing 35 features for each field potential electrode (1995 features for the 57 electrodes in monkey C).  A one-way ANOVA is calculated over all the trials for each feature across reach targets as a method of reduce dimensionality of the input space.  40 features with the lowest p-values are chosen for use in decoding each file.  \\

\noindent
Linear discrminant analysis is applied to these features and ten-fold cross validation evaluates performance.  The mean performance for each file is defined as the fraction of trials that were decoded correctly over the ten test folds.  Chance performance for the center-out task was estimated by randomly shuffling the target labels, and then performing the cross validation.

\section{Nonparametric Bayesian Clustering}

\subsection{Dirichlet process means (DP-means)}
Kulis and Jordan propose "DP-means" which bridges the classic k-means algorithm and the Bayesian nonparametric Dirichlet Process Guassian Mixture Model (DPGMM).  "DP-means" introduces a fixed threshold to determine whether a data point should belong to an existing cluster or a new cluster should be created for it.  The algorithm is layed out as follows: \\

\noindent
\includegraphics{dpmeans.pdf}

\subsection{Pitman Yor Process means (Pyp means)}
\noindent
Fan, Zeng, and Cao (2013) propose a modification to "DP-means" to address issues such as power-law data applicability, over-fitting, and data order-dependence: a modified Pitman-Yor Process based k-means (pyp-means) that can be applied to cluster power-law data and adaptively determine the number of clusters.  Unlike the fixed threshold in \emph{dp-means}, the modified Pitman-Yor-Process defines a variable threshold that is based on the number of existing clusters.  As the cluster number increases, the threshold value and thus, the probability of new cluster generation gets smaller.  \emph{Pyp-means} also introduces a center agglomeration procedure to prevent overfitting.  The procedure computes inter-distance and densities of each cluster pair and combines two clusters in close proximity if they satisfy the agglomeration condition.  Finally, the algorithm employs a heuristic "furthest first" strategy when generating new clusters to tackle the issue that clustering algorithms face with data order.  In summary, the full implementation consists of three procedures:  data partition, center recalculation, and center agglomeration.  The details of the algorithm are shown below:
\subsubsection{Algorithm 1: pyp means}
\noindent
The first algorithm does the initial clustering and leaves points that are too far away from existing center means to be re-clustered in the second algorithm. \\
\includegraphics{pyp1.pdf} 

\subsubsection{Algorithm 2: re-clustering on $D_r$}

The second algorithm uses the "furthest first" heuristic search method as a way to generate clusters uniformly with respect to the order of the data. \\
\includegraphics{pyp2.pdf}

\subsubsection{Center Agglomeration Procedure}
\noindent
The agglomeration procedure check looks as follows for each pair of clusters $i, j$:
$$ ||\mu_1 - \mu_2||^2 < \frac{n_1 + n_2}{n_1 n_2} (\lambda - \theta ln \frac{(c+1)^{(c+1)}}{c^c}) $$
If this condition is satisfied, the two clusters are combined and the mean is recomputed.  The check is done recursively until no pair of clusters satisfy the agglomeration condition.

\pagebreak
\section{Methodology}

\noindent
Analogous to the Flint paper\cite{flint}, the power of LFP frequencies are computed by applying a Hanning window and then applying fast Fourier transforms to 256 windows.  Providing a sample every 100 ms, the windows were overlapepd by 156 ms.  The time of movement onset was estimated using the manipulandum's velocity where the Euclidean norm of the velocity had to be above a fixed threshold (in this case, .0125 for unknown units).  Then, seven time bins from 200 ms before to 500 ms after movement onset are used to compute the LFP power values.  When examining the monkey's hand velocity, this 700 ms period generally embodied the entire reach movement from slow velocity in the right direction of the target to the more rapid reach movement to the slowing of the velocity as the monkey holds the arm position.  Before and after this time period, the hand velocity is much smaller and maybe even in the wrong direction. \\

\noindent
The power of the LFP in the frequency range 0-1000 Hz is computed for this 700 ms period where the range is discretized and linearly spaced into 257 values for the 95 LFP electrodes.  The Flint paper\cite{flint} extracts five features from each field potential signal:  the local motor potential, defined as the moving average within a 256 ms window, and the power in four different frequency bands (0-4, 7-20, 70-200, 200-300 Hz).  They use the power in these bands relative to the power during the period from 2.0 to 1.5 s before movement onset, when the monkey is not reaching.  I choose to compute the rest power of the LFP for the first 700 ms of a trial before a light is flashed.  If a light is illuminated within the first 700 ms of the trial, I examine the LFP for a 700 ms period, 15 ms after the reach-out light is turned off.  As the target light is illuminated between 0.5 and 0.6 s, the monkey's hand velocity dramatically decreases and the monkey seems to return to a "rest" position 15 ms after the reach-out light is turned off.  In reality what is going on is that the monkey has reached the outer target and is maintaining a hold to obtain the liquid reward, which she must do for 200 to 400 ms.  I assume that this "hold" position is similar to the monkey at rest before a trial begins, in terms of brain activity and power of the LFP frequencies . \\

\noindent
The data is then aggregated into a flat vector for each trial/observation.  As there are five features in each of the 7 time bins for 95 electrodes collecting LFPs, there are 3325 features for each trial.  Instead of a one-way ANOVA test on features\cite{flint} for dimensionality reduction, this paper performs principal component analysis (PCA) before moving onto the classification task.  The 3325-length feature vector is reduced to 58 features (I choose to reduce the dimensionality by a factor of $\sqrt{D}$, where $D$ represents the size of the feature space).  After performing an approximate 80-20 split on the data using random sample to partition the train and test sets, I train the data using various classification techniques and evaluate prediction accuracy where the classification error is binary.  I implement Linear Discriminant Analysis (LDA), multi-class Support Vector Machine (SVM)\footnote{The multi-class SVM is an implementation of the libsvm package which employs the 'one-vs.-one' approach for C-classification problems, meaning that k(k-1)/2 binary classifiers are trained and then, the appropriate class is determined by vote.  The SVM uses the radial basis kernel (RBF) with $\gamma=\frac{1}{D}$, where $D$ is the dimensionality of the data, and $C=1$, where $C$ is the coefficient of the slack variables.}
, and k-Nearest Neighbors (k-NN) to train the models.\\

\noindent
The next step is to form clusters based on the Bayesian nonparametric clustering algorithms discussed above.  But I ran into a problem after performing the clustering algorithms:  due to the large number of clusters that had been formed, memory became a valuable and scarce resource.  With feature vectors of lengths greater than 50,000, I found it to be infeasible given the computing power that I was dealing with to be able to train the model, perform the various classification techniques, and evluate if this approach to clustering would have improved classification accuracy. \\

\pagebreak
\section{Results}
\noindent
While there may be fixed feelings about the methodology section, the results seem promising.  With 1281 trials in the full dataset, the 80-20 training-split left 256 cases for testing.  Before applying PCA, I perform the classification and achieve the following results after 10 runs:  90.23\% accuracy (231/256 correctly identified) with L.D.A., 85.23\% accuracy with k-NN (218.2/256 on average).  After reducing the dimensionality of the data by considering the first 58 principal components, I re-try the classification task and run it 100 times.  The LDA averages 239.16 correct classifications (93.42\%) whereas the k-NN accurately predicts 217.78 (85.07\%) out of the 256 test cases.  While the multi-class SVM was not run with the full dataset, it performed almost as well as the LDA averaging 235.38 correct classifications out of 256 (91.95\%).  \\

\noindent
These results demonstrate stronger prediction accuracies than that of the given methodology\cite{flint}\footnote{Flint et. all accurately classify the target at a rate of 86\%.}.  It is evident that these classifiers were effective as the class distributions were quite even:  \\
\noindent
\begin{table}[h]
\begin{tabular}{lllllllll}
1   & 2   & 3   & 4   & 5   & 6   & 7   & 8   \\
NW  & N   & NE  & W   & E   & SW  & S   & SE  \\
168 & 167 & 151 & 163 & 166 & 163 & 153 & 150
\end{tabular}
\end{table}

\section{Future work}
\noindent
\begin{centering}
\includegraphics[scale=0.5]{e5.pdf}
\end{centering}
This is a plot demonstrating the distribution of frequencies for one of the data files.  It is evident that the distribution of ferquency amplitudes can be characterized by a power-law distribution.   Thus, the B.N.P. approach to clustering the frequencies appears to be an appropriate choice.  It is to be determined whether this perhaps more thoughtful approach to binning the data would improve prediction performance.  Certainly, the next step beyond performing classification would be to predict reach movement details such as position, velocity, and acceleration and use more sophisticated machine learning algorithms when performing these tasks.


\begin{thebibliography}{9}

\bibitem{flint}
Flint, Robert D., Lindberg, Eric W., Jordan, Luke R., Miller, Lee E., and Slutzky, Marc W. (2012) Accurate decoding of reaching movements from field potentials in the absence of spikes.  Journal of Neural Engineering 9: 046006. 

\bibitem{pyp}
Fan, Xuhui, Zeng, Yiling, Cao, Longbing. (2013) Non-parametric Power-law Data Clustering.  arXiv:1306.3003.

\end{thebibliography}
\end{document}